{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from importlib.util import find_spec\n",
    "if find_spec(\"text_recognizer\") is None:\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "\n",
    "from text_recognizer.datasets.emnist_dataset import EmnistDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0], True)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMNIST Dataset\n",
      "Num classes: 62\n",
      "Mapping: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N', 24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U', 31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b', 38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i', 45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p', 52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w', 59: 'x', 60: 'y', 61: 'z'}\n",
      "Input shape: [28, 28]\n",
      "\n",
      "(84074, 28, 28) (84074, 62)\n",
      "(13947, 28, 28) (13947, 62)\n"
     ]
    }
   ],
   "source": [
    "dataset = EmnistDataset(subsample_fraction=0.25)\n",
    "dataset.load_or_generate_data()\n",
    "print(dataset)\n",
    "print(dataset.x_train.shape, dataset.y_train.shape)\n",
    "print(dataset.x_test.shape, dataset.y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "expand_dims (Lambda)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 62)                7998      \n",
      "=================================================================\n",
      "Total params: 1,206,590\n",
      "Trainable params: 1,206,590\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from text_recognizer.networks.lenet import lenet\n",
    "\n",
    "network = lenet(dataset.input_shape, output_shape=(dataset.num_classes, 1))\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1314/1314 [==============================] - 5s 4ms/step - loss: 0.3654 - accuracy: 0.9167 - val_loss: 0.0732 - val_accuracy: 0.9788\n",
      "Epoch 2/5\n",
      "1314/1314 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9762 - val_loss: 0.0591 - val_accuracy: 0.9822\n",
      "Epoch 3/5\n",
      "1314/1314 [==============================] - 5s 3ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0455 - val_accuracy: 0.9865\n",
      "Epoch 4/5\n",
      "1314/1314 [==============================] - 5s 4ms/step - loss: 0.0482 - accuracy: 0.9854 - val_loss: 0.0327 - val_accuracy: 0.9900\n",
      "Epoch 5/5\n",
      "1314/1314 [==============================] - 5s 3ms/step - loss: 0.0406 - accuracy: 0.9873 - val_loss: 0.0327 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f09dc0c5c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.compile(optimizer='sgd', loss='categorical_crossentropy', metrics='accuracy')\n",
    "network.fit(\n",
    "    x=dataset.x_train,\n",
    "    y=dataset.y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    validation_data=(dataset.x_test, dataset.y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "[[9.99999523e-01 5.00053732e-09 5.34690173e-07 4.33240915e-10\n",
      "  5.36466072e-09 8.73429662e-10 4.37479564e-08 1.23378130e-09\n",
      "  1.10728049e-08 1.77422692e-13 1.73106366e-15 8.80899357e-15\n",
      "  5.05052684e-12 1.29500242e-14 2.76758027e-13 2.74695834e-14\n",
      "  5.34096638e-12 6.90764051e-15 1.55612294e-11 1.65399760e-17\n",
      "  3.71540441e-16 5.13859585e-14 1.06197577e-14 2.66463284e-14\n",
      "  6.26649137e-14 1.23309430e-13 8.11075653e-14 1.42759797e-14\n",
      "  2.74568562e-10 1.85377172e-13 3.64802225e-15 9.96187707e-17\n",
      "  1.38986606e-16 8.89908239e-20 2.36341335e-15 1.02858604e-10\n",
      "  6.93700460e-15 1.68719119e-11 7.71908470e-17 2.75828180e-11\n",
      "  7.63461085e-14 1.65765825e-13 5.41621801e-14 4.84974994e-12\n",
      "  2.44462055e-11 1.98915182e-17 1.26791210e-14 8.94500606e-14\n",
      "  3.69860705e-11 9.72429399e-15 1.96485470e-15 8.70255951e-12\n",
      "  4.73197106e-11 4.89993289e-11 2.13393114e-20 2.93501522e-16\n",
      "  1.69292835e-12 9.59823401e-11 1.40715699e-15 2.92891427e-12\n",
      "  1.44630893e-14 2.16170520e-13]]\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_example = dataset.x_test[0:1]\n",
    "plt.matshow(x_example[0])\n",
    "\n",
    "x_example = np.expand_dims(x_example, -1)\n",
    "print(x_example.shape)\n",
    "preds = network.predict(x_example)\n",
    "print(preds)\n",
    "\n",
    "ind = np.argmax(preds)\n",
    "print(ind)\n",
    "\n",
    "print(dataset.mapping[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
